{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d89bed-4f2a-45c5-b5a6-2b8f024c0c7a",
   "metadata": {},
   "source": [
    "# **LLM-BASED MEDIA RECOMMENDER SYSTEM**\n",
    "\n",
    "## **Summary**\n",
    "\n",
    "This notebook presents a study exploring the use of Large Language Models (LLMs) as zero-shot recommendation engines across three media domains: anime, books, and movies.\n",
    "\n",
    "We use publicly available datasets from Kaggle containing metadata and synopses. The workflow for each domain is as follows:\n",
    "\n",
    "1. The user provides a natural language prompt describing their current mood or preferences.\n",
    "2. We embed both the prompt and all item descriptions using `all-MiniLM-L6-v2` from the SentenceTransformers library.\n",
    "3. Cosine similarity is computed between the user input and each item‚Äôs synopsis to shortlist the top 15 most relevant titles.\n",
    "4. These 15 items are passed as context to `gpt-3.5-turbo`, which selects and justifies one final recommendation.\n",
    "5. We evaluate the results using two cosine similarity scores:\n",
    "   - Between the user prompt and the recommended **synopsis**.\n",
    "   - Between the user prompt and the GPT-generated **justification/reasoning**.\n",
    "\n",
    "This project aims to assess how well LLMs can perform personalized media recommendations without explicit training, using only natural language inputs and existing content metadata.\n",
    "\n",
    "## **Datasets**\n",
    "\n",
    "- Animes: https://www.kaggle.com/datasets/tanishksharma9905/top-popular-anime\n",
    "- Books: https://www.kaggle.com/datasets/abdallahwagih/books-dataset\n",
    "- Movies: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc730c20-c176-4b05-86a8-d94f52baea26",
   "metadata": {},
   "source": [
    "## **Data Formatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caf0e15f-f27a-41b2-8551-02f90bfb5537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anime entries: 28825\n",
      "Columns: Index(['id', 'name', 'genres', 'type', 'episodes', 'status', 'aired_from',\n",
      "       'aired_to', 'duration_per_ep', 'score', 'scored_by', 'rank', 'rating',\n",
      "       'studios', 'producers', 'image', 'trailer', 'synopsis'],\n",
      "      dtype='object')\n",
      "\n",
      "Sample formatted anime entry:\n",
      "\n",
      "Title: Frieren: Beyond Journey's End\n",
      "Genres: Adventure, Drama, Fantasy\n",
      "Score: 9.3\n",
      "Synopsis: During their decade-long quest to defeat the Demon King, the members of the hero's party‚ÄîHimmel himself, the priest Heiter, the dwarf warrior Eisen, and the elven mage Frieren‚Äîforge bonds through adventures and battles, creating unforgettable precious memories for most of them.\n",
      "\n",
      "However, the time that Frieren spends with her comrades is equivalent to merely a fraction of her life, which has lasted over a thousand years. When the party disbands after their victory, Frieren casually returns to her \"usual\" routine of collecting spells across the continent. Due to her different sense of time, she seemingly holds no strong feelings toward the experiences she went through.\n",
      "\n",
      "As the years pass, Frieren gradually realizes how her days in the hero's party truly impacted her. Witnessing the deaths of two of her former companions, Frieren begins to regret having taken their presence for granted; she vows to better understand humans and create real personal connections. Although the story of that once memorable journey has long ended, a new tale is about to begin.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anime_df = pd.read_csv(\"popular_anime.csv\")\n",
    "\n",
    "# Check total entries and columns\n",
    "print(\"Total anime entries:\", len(anime_df))\n",
    "print(\"Columns:\", anime_df.columns)\n",
    "\n",
    "# Select and rename relevant columns\n",
    "anime_df = anime_df[['name', 'genres', 'synopsis', 'score']].dropna()\n",
    "anime_df.columns = ['Title', 'Genres', 'Synopsis', 'Score']\n",
    "\n",
    "# Sort by score \n",
    "anime_df = anime_df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Format as list of strings for LLM input\n",
    "anime_data = []\n",
    "for _, row in anime_df.iterrows():\n",
    "    entry = f\"\"\"Title: {row['Title']}\n",
    "Genres: {row['Genres']}\n",
    "Score: {row['Score']}\n",
    "Synopsis: {row['Synopsis']}\"\"\"\n",
    "    anime_data.append(entry)\n",
    "\n",
    "# sample\n",
    "print(\"\\nSample formatted anime entry:\\n\")\n",
    "print(anime_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0679afa-c38d-4f01-97a5-a117152e22c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books entries: 6810\n",
      "Columns: Index(['isbn13', 'isbn10', 'title', 'subtitle', 'authors', 'categories',\n",
      "       'thumbnail', 'description', 'published_year', 'average_rating',\n",
      "       'num_pages', 'ratings_count'],\n",
      "      dtype='object')\n",
      "\n",
      "Sample formatted book entry:\n",
      "\n",
      "Title: Bill Gates\n",
      "Author: Sara Barton-Wood\n",
      "Rating: 5.0\n",
      "Genres: Juvenile Nonfiction\n",
      "Description: Presents the life of Bill Gates, from his childhood, to his education, and to his days as mastermind and head of Microsoft a multi-billion dollar computer software company.\n"
     ]
    }
   ],
   "source": [
    "books_df = pd.read_csv(\"books_data.csv\")\n",
    "\n",
    "# Inspect basic info\n",
    "print(\"Total books entries:\", len(books_df))\n",
    "print(\"Columns:\", books_df.columns)\n",
    "\n",
    "# Keep only the relevant columns\n",
    "books_df = books_df[['title', 'authors', 'description', 'average_rating', 'categories']].dropna()\n",
    "books_df.columns = ['Title', 'Author', 'Description', 'Rating', 'Genres']\n",
    "\n",
    "# Sort by rating\n",
    "books_df = books_df.sort_values(by='Rating', ascending=False)\n",
    "\n",
    "# Format as list of strings for LLM input\n",
    "books_data = []\n",
    "for _, row in books_df.iterrows():\n",
    "    entry = f\"\"\"Title: {row['Title']}\n",
    "Author: {row['Author']}\n",
    "Rating: {row['Rating']}\n",
    "Genres: {row['Genres']}\n",
    "Description: {row['Description']}\"\"\"\n",
    "    books_data.append(entry)\n",
    "\n",
    "# sample\n",
    "print(\"\\nSample formatted book entry:\\n\")\n",
    "print(books_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecfabcc3-8521-48c4-9647-8e391b99d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movie entries: 45466\n",
      "Columns: Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='object')\n",
      "\n",
      "Sample formatted movie entry:\n",
      "\n",
      "Title: Pourquoi Isra√´l\n",
      "Genres: Documentary\n",
      "Rating: 10.0\n",
      "Description: Using interviews and other footage shot especially for this documentary, French director Claude Lanzmann investigates the state of Israel in 1972. This movie concentrates on Israelis going about their business of everyday living.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "  \n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# Show basic info\n",
    "print(\"Total movie entries:\", len(movies_df))\n",
    "print(\"Columns:\", movies_df.columns)\n",
    "\n",
    "# Filter out bad rows\n",
    "movies_df = movies_df[['title', 'overview', 'vote_average', 'genres']].dropna()\n",
    "movies_df = movies_df[movies_df['vote_average'] > 0]\n",
    "\n",
    "# Process genres column: convert stringified list of dicts to comma-separated string\n",
    "def extract_genres(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return \", \".join([g['name'] for g in genres])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "movies_df['genres'] = movies_df['genres'].apply(extract_genres)\n",
    "\n",
    "# Rename for consistency\n",
    "movies_df.columns = ['Title', 'Description', 'Rating', 'Genres']\n",
    "\n",
    "# Sort by rating\n",
    "movies_df = movies_df.sort_values(by='Rating', ascending=False)\n",
    "\n",
    "# Format into LLM-friendly prompt entries\n",
    "movies_data = []\n",
    "for _, row in movies_df.iterrows():\n",
    "    entry = f\"\"\"Title: {row['Title']}\n",
    "Genres: {row['Genres']}\n",
    "Rating: {row['Rating']}\n",
    "Description: {row['Description']}\"\"\"\n",
    "    movies_data.append(entry)\n",
    "\n",
    "# sample\n",
    "print(\"\\nSample formatted movie entry:\\n\")\n",
    "print(movies_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2f9047-08a3-49ce-ac82-a31d7896974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41710 entries, 32949 to 25444\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Title        41710 non-null  object \n",
      " 1   Description  41710 non-null  object \n",
      " 2   Rating       41710 non-null  float64\n",
      " 3   Genres       41710 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a65ec-7d68-4e77-aa8f-f5861e3529f2",
   "metadata": {},
   "source": [
    "## **Feasibility: testing on a small sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5b6db82-eb31-4dc6-a975-3d656750ec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from openai) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a683cb46-cb1b-4c2c-98c7-8f79153afdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Recommended Anime:\n",
      "\n",
      "Based on your preferences for a dramatic and psychological anime with a strong female lead, I recommend **\"A Silent Voice\"**. \n",
      "\n",
      "**Title: A Silent Voice**  \n",
      "**Genres:** Drama, Award Winning  \n",
      "**Synopsis:** Shouya Ishida, a former elementary school student, seeks redemption after bullying a deaf classmate named Shouko Nishimiya. Years later, Shouya is plagued by his past actions and sets out to make amends by reconnecting with Shouko. The anime explores themes of guilt, forgiveness, redemption, and the complexities of human relationships. The strong female lead, Shouko, showcases resilience and compassion in the face of adversity, making her a compelling character to follow.\n",
      "\n",
      "**Why you should watch it:**  \n",
      "1. **Emotional Depth:** \"A Silent Voice\" delves into heavy themes like bullying, mental health, and redemption, offering a poignant and emotional viewing experience.\n",
      "2. **Character Development:** The characters undergo significant growth and introspection throughout the story, providing a deep exploration of human emotions and relationships.\n",
      "3. **Strong Female Lead:** Shouko Nishimiya is a well-developed and resilient character who navigates complex emotions and challenges with grace and strength.\n",
      "4. **Psychological Themes:** The anime explores the psychological impact of past actions, guilt, and the journey towards self-forgiveness and acceptance.\n",
      "5. **Award-Winning:** The anime has received critical acclaim for its storytelling, animation, and portrayal of sensitive themes, making it a must-watch for fans of drama and psychological narratives.\n",
      "\n",
      "\"A Silent Voice\" offers a moving and thought-provoking narrative with a focus on character development and emotional depth, making it a compelling choice for your current preferences.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import random\n",
    "\n",
    "# Set API key\n",
    "openai.api_key = \"My_API_Key\" #Removed the actual key for security purposes\n",
    "\n",
    "#  Prepare the top anime dataset (limit to top 50 based on score)\n",
    "top_anime_df = anime_df.sort_values(by=\"Score\", ascending=False).dropna().head(50)\n",
    "\n",
    "# Create a function to turn the dataframe into a prompt string\n",
    "def build_anime_context(df):\n",
    "    context = \"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        entry = f\"Title: {row['Title']}\\nGenres: {row['Genres']}\\nSynopsis: {row['Synopsis']}\\nScore: {row['Score']}\\n\"\n",
    "        context += entry + \"\\n---\\n\"\n",
    "    return context\n",
    "\n",
    "anime_context = build_anime_context(top_anime_df)\n",
    "\n",
    "# Function to ask LLM to recommend\n",
    "def recommend_anime(user_prompt, context):\n",
    "    system_msg = \"You are a recommendation system that suggests anime based on the user's preferences using the provided list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is a list of anime:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"My preferences: {user_prompt}\\nBased on the above list, which anime should I watch and why?\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# usage\n",
    "user_input = \"I'm in the mood for something dramatic and psychological with a strong female lead\"\n",
    "response = recommend_anime(user_input, anime_context)\n",
    "print(\"\\n Recommended Anime:\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba34987-edc5-42fb-9b0e-ea7dc26677bc",
   "metadata": {},
   "source": [
    "## **Production / Prototype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cef30060-4091-4691-bb79-f854a5aadd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.34.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading huggingface_hub-0.34.2-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.54.0-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed hf-xet-1.1.5 huggingface-hub-0.34.2 safetensors-0.5.3 sentence_transformers-5.0.0 tokenizers-0.21.4 transformers-4.54.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3f70f67-d621-4be4-89c9-e6f551c2c693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /opt/anaconda3/lib/python3.12/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66861ea5-f0f0-4c50-9124-935990d51b2a",
   "metadata": {},
   "source": [
    "### **Animes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0fac380c-863f-4086-89d6-1bea237dfa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend you watch \"Sentimental Journey\".\n",
      "\n",
      "Title: Sentimental Journey\n",
      "Genres: Drama, Romance\n",
      "Synopsis: Sentimental Journey is a collection of twelve short stories about twelve different girls. Though unrelated, there is one common theme that binds the episodes together: each girl's bittersweet experience of f\n",
      "\n",
      "Reasoning:\n",
      "\"Sentimental Journey\" fits your preference for something dramatic and psychological with a strong female lead. Each story in this anime focuses on a different girl and her emotional journey, allowing for a deep exploration of complex feelings and experiences. The series delves into themes of love, loss, and personal growth, offering a poignant and reflective look at the lives of the female characters. The strong emotional depth and psychological introspection make \"Sentimental Journey\" a compelling choice for viewers seeking a dramatic and thought-provoking anime with a focus on female protagonists.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# USER PROMPT\n",
    "user_prompt = \"I'm in the mood for something dramatic and psychological with a strong female lead\"\n",
    "\n",
    "# Embed all anime synopses\n",
    "synopses = anime_df['Synopsis'].fillna(\"\").tolist()\n",
    "synopsis_embeddings = embedder.encode(synopses, convert_to_tensor=True)\n",
    "\n",
    "# Embed the user input\n",
    "user_embedding = embedder.encode(user_prompt, convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity\n",
    "cos_similarities = cosine_similarity(\n",
    "    user_embedding.cpu().numpy().reshape(1, -1),\n",
    "    synopsis_embeddings.cpu().numpy()\n",
    ")[0]\n",
    "\n",
    "# Get top 15 most relevant anime\n",
    "top_indices = np.argsort(cos_similarities)[::-1][:15]\n",
    "top_anime_df = anime_df.iloc[top_indices]\n",
    "\n",
    "\n",
    "# Format the context for GPT\n",
    "anime_context = \"\\n\\n\".join(\n",
    "    f\"Title: {row['Title']}\\nGenres: {row['Genres']}\\nSynopsis: {row['Synopsis']}\"\n",
    "    for _, row in top_anime_df.iterrows()\n",
    ")\n",
    "\n",
    "# Ask GPT for a recommendation from the shortlist\n",
    "def recommend_anime(user_prompt, context):\n",
    "    system_msg = \"You are a recommendation system that selects the best anime based on user preferences and explains your choice. Only use the provided list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is a list of anime:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"My preferences: {user_prompt}\\nWhich anime should I watch and why? Provide the title, genres, synopsis, and your reasoning.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Get recommendation\n",
    "response = recommend_anime(user_prompt, anime_context)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e422637d-34c8-4139-a112-f06e384f2a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Synopsis Similarity Score: 0.415\n",
      " Justification Similarity Score: 0.521\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract Synopsis\n",
    "synopsis_match = re.search(r\"Synopsis:\\s*(.+?)\\n(?:Justification|Reasoning|$)\", response, re.DOTALL)\n",
    "if synopsis_match:\n",
    "    recommended_synopsis = synopsis_match.group(1).strip()\n",
    "else:\n",
    "    recommended_synopsis = None\n",
    "\n",
    "#  Extract Justification\n",
    "justification_match = re.search(r\"(Justification|Reasoning):\\s*(.+)\", response, re.DOTALL)\n",
    "if justification_match:\n",
    "    recommended_justification = justification_match.group(2).strip()\n",
    "else:\n",
    "    recommended_justification = None\n",
    "\n",
    "# Compute Similarity Scores\n",
    "if recommended_synopsis:\n",
    "    synopsis_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_synopsis])\n",
    "    )[0][0]\n",
    "    print(f\" Synopsis Similarity Score: {synopsis_score:.3f}\")\n",
    "else:\n",
    "    print(\" Could not extract synopsis.\")\n",
    "\n",
    "if recommended_justification:\n",
    "    justification_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_justification])\n",
    "    )[0][0]\n",
    "    print(f\" Justification Similarity Score: {justification_score:.3f}\")\n",
    "else:\n",
    "    print(\" Could not extract justification.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88433072-7b07-4217-9433-7ebf45c060ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d2c4dee5-3681-46f4-b4bb-e119e37bf7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Colorful\n",
      "\n",
      "Genres: Comedy, Ecchi\n",
      "\n",
      "Synopsis: Colorful! contains over 50 vignettes of men, women, and the pursuit of various comedic and risqu√© situations. From unexpected encounters on subways to panty-obsessed video geeks, this anime offers a strange, deranged, racy, and hilarious dose of animated chaos. It explores a wide range of scenarios involving quirky characters and bizarre situations, providing a mix of humor and ecchi elements.\n",
      "\n",
      "Reasoning: If you're in the mood for something chaotic, Colorful is a perfect choice due to its diverse and eccentric collection of short stories. The anime presents a wide array of characters and situations that are bound to keep you entertained and surprised with its unconventional and humorous take on everyday occurrences. The blend of comedy and ecchi elements adds an extra layer of unpredictability and fun to the chaotic nature of the anime, making it an enjoyable watch for those seeking an animated rollercoaster of absurdity and laughter.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"I'm in the mood for something chaotic\"\n",
    "\n",
    "def recommend_anime(user_prompt, context):\n",
    "    system_msg = \"You are a recommendation system that selects the best anime based on user preferences and explains your choice. Only use the provided list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is a list of anime:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"My preferences: {user_prompt}\\nWhich anime should I watch and why? Provide the title, genres, synopsis, and your reasoning.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Get recommendation\n",
    "response = recommend_anime(user_prompt, anime_context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fb0615b4-7b98-439d-afe8-2a82e5ca5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Synopsis Similarity Score: 0.376\n",
      " Justification Similarity Score: 0.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "synopsis_match = re.search(r\"Synopsis:\\s*(.+?)\\n(?:Justification|Reasoning|$)\", response, re.DOTALL)\n",
    "if synopsis_match:\n",
    "    recommended_synopsis = synopsis_match.group(1).strip()\n",
    "else:\n",
    "    recommended_synopsis = None\n",
    "\n",
    "\n",
    "justification_match = re.search(r\"(Justification|Reasoning):\\s*(.+)\", response, re.DOTALL)\n",
    "if justification_match:\n",
    "    recommended_justification = justification_match.group(2).strip()\n",
    "else:\n",
    "    recommended_justification = None\n",
    "\n",
    "if recommended_synopsis:\n",
    "    synopsis_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_synopsis])\n",
    "    )[0][0]\n",
    "    print(f\" Synopsis Similarity Score: {synopsis_score:.3f}\")\n",
    "else:\n",
    "    print(\" Could not extract synopsis.\")\n",
    "\n",
    "if recommended_justification:\n",
    "    justification_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_justification])\n",
    "    )[0][0]\n",
    "    print(f\" Justification Similarity Score: {justification_score:.3f}\")\n",
    "else:\n",
    "    print(\" Could not extract justification.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15aa798-ae00-443b-813d-37b0075eb467",
   "metadata": {},
   "source": [
    "### **Why Cosine Similarity?** : \n",
    "Cosine similarity is a metric that measures how similar two vectors are, based on the angle between them. It‚Äôs widely used in natural language processing to compare text embeddings, like comparing a mood prompt to a book or movie synopsis.\n",
    "\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "1. **Text is converted into vectors**\n",
    "   Using a model like `SentenceTransformer`, the input (e.g., \"I want something dark and emotional\") and a synopsis are transformed into high-dimensional vectors (embeddings). These vectors capture the semantic meaning of the text.\n",
    "\n",
    "2. **Cosine similarity measures the angle**\n",
    "\n",
    "   * A cosine of **1.0** means the vectors are pointing in the same direction ‚Üí **perfect match**.\n",
    "   * A cosine of **0.0** means the vectors are orthogonal ‚Üí **no similarity**.\n",
    "   * A cosine of **-1.0** means they're opposite ‚Üí **completely different**.\n",
    "\n",
    "3. **Formula**\n",
    "\n",
    "   $$\n",
    "   \\text{cosine\\_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "   $$\n",
    "\n",
    "   Where:\n",
    "\n",
    "   * $A \\cdot B$ is the **dot product** of the vectors\n",
    "   * $\\|A\\|$ and $\\|B\\|$ are their magnitudes (lengths)\n",
    "\n",
    "### Why it‚Äôs useful for the project:\n",
    "\n",
    "* It helps **quantify** how well the LLM‚Äôs recommended synopsis matches the intent.\n",
    "* It provides an **objective metric** to compare different recommendation methods.\n",
    "* It can be used to **evaluate accuracy** even when there‚Äôs no labeled ground truth.\n",
    "\n",
    "\n",
    "In this case, a **higher cosine similarity score** (closer to 1) means the anime/book/movie recommendation is semantically close to what the user said they wanted, even if the words used are different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150a22e-ecfc-48d0-8dc5-a8903f42653a",
   "metadata": {},
   "source": [
    "### **Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5e42eeb8-c38f-4e33-ad71-d133854e84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Shadow of the Wind\n",
      "Genres: Fiction\n",
      "Synopsis: The international literary sensation--a runaway bestseller in Spain--is about a boy's quest through the secrets and shadows of postwar Barcelona for a mysterious author whose book has proved as dangerous to own as it is impossible to forget.\n",
      "Reasoning: \"The Shadow of the Wind\" is the perfect choice for you as it combines mystery, intrigue, and deep character development. The novel is set in a postwar Barcelona filled with secrets and shadows, following a boy's quest to uncover the mysteries surrounding a mysterious author and his dangerous book. The story delves into complex characters, their hidden pasts, and the interconnectedness of their lives, offering a thought-provoking and immersive reading experience. The richly developed characters, along with the atmospheric setting and intricate plot, make this book a compelling and engrossing read that will satisfy your desire for mystery and deep character exploration.\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# USER PROMPT\n",
    "user_prompt = \"I want to read something mysterious and thought-provoking with deep character development\"\n",
    "\n",
    "# Embed all book synopses\n",
    "synopses = books_df['Description'].fillna(\"\").tolist()\n",
    "synopsis_embeddings = embedder.encode(synopses, convert_to_tensor=True)\n",
    "\n",
    "# Embed the user input\n",
    "user_embedding = embedder.encode(user_prompt, convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity\n",
    "cos_similarities = cosine_similarity(\n",
    "    user_embedding.cpu().numpy().reshape(1, -1),\n",
    "    synopsis_embeddings.cpu().numpy()\n",
    ")[0]\n",
    "\n",
    "# Get top 15 most relevant books\n",
    "top_indices = np.argsort(cos_similarities)[::-1][:15]\n",
    "top_books_df = books_df.iloc[top_indices]\n",
    "\n",
    "# Format the context for GPT\n",
    "book_context = \"\\n\\n\".join(\n",
    "    f\"Title: {row['Title']}\\nGenres: {row['Genres']}\\nSynopsis: {row['Description']}\"\n",
    "    for _, row in top_books_df.iterrows()\n",
    ")\n",
    "\n",
    "# Ask GPT for a recommendation\n",
    "def recommend_book(user_prompt, context):\n",
    "    system_msg = \"You are a book recommendation system that selects the best book based on user preferences and explains your choice. Only use the provided list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is a list of books:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"My preferences: {user_prompt}\\nWhich book should I read and why? Provide the title, genres, synopsis, and your reasoning.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Get recommendation\n",
    "response = recommend_book(user_prompt, book_context)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5fda1e29-c8d8-4b31-a625-f86efeb7cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Synopsis Similarity Score: 0.503\n",
      " Justification Similarity Score: 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "synopsis_match = re.search(r\"Synopsis:\\s*(.+?)\\n(?:Justification|Reasoning|$)\", response, re.DOTALL)\n",
    "if synopsis_match:\n",
    "    recommended_synopsis = synopsis_match.group(1).strip()\n",
    "else:\n",
    "    recommended_synopsis = None\n",
    "\n",
    "\n",
    "justification_match = re.search(r\"(Justification|Reasoning):\\s*(.+)\", response, re.DOTALL)\n",
    "if justification_match:\n",
    "    recommended_justification = justification_match.group(2).strip()\n",
    "else:\n",
    "    recommended_justification = None\n",
    "\n",
    "\n",
    "if recommended_synopsis:\n",
    "    synopsis_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_synopsis])\n",
    "    )[0][0]\n",
    "    print(f\"\\n Synopsis Similarity Score: {synopsis_score:.3f}\")\n",
    "else:\n",
    "    print(\"\\n Could not extract synopsis for similarity calculation.\")\n",
    "\n",
    "# --- Compute cosine similarity for justification\n",
    "if recommended_justification:\n",
    "    justification_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_justification])\n",
    "    )[0][0]\n",
    "    print(f\" Justification Similarity Score: {justification_score:.3f}\")\n",
    "else:\n",
    "    print(\"\\n Could not extract justification for similarity calculation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04c17b-c0c5-4012-9004-e7f44d31b797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9b48e07-42b2-4284-9c9f-89126a22640d",
   "metadata": {},
   "source": [
    "### **Movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ad707ace-ffa9-4fe0-9b93-d9055baaf350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Dark Below\n",
      "Genres: Thriller\n",
      "Overview: The Dark Below is an experimental thriller set on Michigan's Great Lakes.\n",
      "\n",
      "Justification: \"The Dark Below\" fits your preferences as it is a suspenseful thriller that offers a dark atmosphere and emotional depth. The experimental nature of the film adds an intriguing layer to the storytelling, making it a unique and captivating watch for those looking for a gripping and atmospheric thriller experience.\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# USER PROMPT\n",
    "user_prompt = \"I'm in the mood for a suspenseful thriller with emotional depth and a dark atmosphere\"\n",
    "\n",
    "# Embed all movie overviews\n",
    "overviews = movies_df['Description'].fillna(\"\").tolist()\n",
    "overview_embeddings = embedder.encode(overviews, convert_to_tensor=True)\n",
    "\n",
    "# Embed user input\n",
    "user_embedding = embedder.encode(user_prompt, convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity\n",
    "cos_similarities = cosine_similarity(\n",
    "    user_embedding.cpu().numpy().reshape(1, -1),\n",
    "    overview_embeddings.cpu().numpy()\n",
    ")[0]\n",
    "\n",
    "# Get top 15 relevant movies\n",
    "top_indices = np.argsort(cos_similarities)[::-1][:15]\n",
    "top_movies_df = movies_df.iloc[top_indices]\n",
    "\n",
    "# Format GPT context\n",
    "movie_context = \"\\n\\n\".join(\n",
    "    f\"Title: {row['Title']}\\nGenres: {row['Genres']}\\nOverview: {row['Description']}\"\n",
    "    for _, row in top_movies_df.iterrows()\n",
    ")\n",
    "\n",
    "# Ask GPT to recommend one\n",
    "def recommend_movie(user_prompt, context):\n",
    "    system_msg = \"You are a movie recommendation system that selects one movie from the list and explains why it's a good match. Only use the provided list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is a list of movies:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"My preferences: {user_prompt}\\nWhich movie should I watch and why? Return the title, genres, overview, and justification.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# recommendation\n",
    "response = recommend_movie(user_prompt, movie_context)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "638401ed-f59e-4856-8361-7c02cd88438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Synopsis Similarity Score: 0.515\n",
      " Justification Similarity Score: 0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "synopsis_match = re.search(r\"Overview:\\s*(.+?)\\n(?:Justification|Reasoning|$)\", response, re.DOTALL)\n",
    "if synopsis_match:\n",
    "    recommended_synopsis = synopsis_match.group(1).strip()\n",
    "else:\n",
    "    recommended_synopsis = None\n",
    "\n",
    "\n",
    "justification_match = re.search(r\"(Justification|Reasoning):\\s*(.+)\", response, re.DOTALL)\n",
    "if justification_match:\n",
    "    recommended_justification = justification_match.group(2).strip()\n",
    "else:\n",
    "    recommended_justification = None\n",
    "\n",
    "\n",
    "if recommended_synopsis:\n",
    "    synopsis_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_synopsis])\n",
    "    )[0][0]\n",
    "    print(f\"\\n Synopsis Similarity Score: {synopsis_score:.3f}\")\n",
    "else:\n",
    "    print(\"\\n Could not extract synopsis for similarity calculation.\")\n",
    "\n",
    "#  Compute cosine similarity for justification\n",
    "if recommended_justification:\n",
    "    justification_score = cosine_similarity(\n",
    "        embedder.encode([user_prompt]),\n",
    "        embedder.encode([recommended_justification])\n",
    "    )[0][0]\n",
    "    print(f\" Justification Similarity Score: {justification_score:.3f}\")\n",
    "else:\n",
    "    print(\"\\n Could not extract justification for similarity calculation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596279a-009f-40e5-8d2f-938ad01b2293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
